{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einleitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Toy Projekt arbeiten wir mit Tweets von amerikanischen Politikern. Wir wollen einmal sehen, ob es möglich ist, den typischen Tweet-Style des amerikanischen Chefpolitikers mit Machine Learning zu erkennen und seine Tweets von anderen zu unterscheiden.\n",
    "\n",
    "Dafür verwenden wir den Cloud-Dienst [Monkeylearn](https://monkeylearn.com). Monkeylearn hat sich auf Natural Language Processing spezialisiert, und bietet eine Vielzahl an vorkonfigurierten Klassifiern, die man mit eigenen Daten trainieren und verwenden kann."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsere Daten holen wir aus dem [Trump Twitter Archive](http://www.trumptwitterarchive.com/). Direkte Downloads von Archiven sind [hier](https://github.com/bpb27/trump-tweet-archive) und weitere Archive sind [hier](https://github.com/bpb27/political_twitter_archive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Einige Archive sind bereits im Docker Image drin:\n",
    "!ls /data/data/tweets/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zuerst laden wir die Daten von Donald Trump:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/data/data/tweets/donald_trump/condensed_2016.json', 'r') as f:\n",
    "    trump_tweets = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun laden wir die Daten von Ben Carson, einem weiteren Republikaner. Wir wählen bewusst zwei Republikaner. Mit Trump und einem Demokraten wäre die Aufgabe wohl etwas zu einfach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/data/data/tweets/others/realbencarson_short.json', 'r') as f:\n",
    "    other_tweets = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schauen wir uns die Struktur mal an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trump_tweets[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es interessieren uns lediglich `text` und `is_retweet`. Wir säubern nun die Daten ein wenig. Zum Beispiel entfernen wir Links, @mentions, Hashtags. Dies wiederum, um dem Algorithmus die Sache nicht zu einfach zu machen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def filter_and_clean_tweets(j):\n",
    "    \"\"\"Filter out retweets and clean remaining tweets\n",
    "    downloaded from http://www.trumptwitterarchive.com/ a bit\n",
    "    \"\"\"\n",
    "    \n",
    "    # filter out retweets and extract tweet text\n",
    "    tweets = [entry['text'] for entry in j if not entry['is_retweet']]\n",
    "\n",
    "    # replace \\n by space\n",
    "    tweets = [re.sub(r'\\n', ' ', tweet) for tweet in tweets]\n",
    "\n",
    "    # remove double quotes\n",
    "    tweets = [re.sub(r'\"', '', tweet) for tweet in tweets]\n",
    "\n",
    "    # remove leading dot\n",
    "    tweets = [re.sub(r'^\\.', '', tweet) for tweet in tweets]\n",
    "\n",
    "    # remove 'RT ' at beginning\n",
    "    tweets = [re.sub(r'^RT\\s*', '', tweet) for tweet in tweets] \n",
    "\n",
    "    # remove @mentions\n",
    "    tweets = [re.sub(r'@\\w+:?', r'', tweet) for tweet in tweets] \n",
    "\n",
    "    # remove hashtags\n",
    "    tweets = [re.sub(r'#\\w+:?', r'', tweet) for tweet in tweets]\n",
    "\n",
    "    # remove links (do it several times to catch them all)\n",
    "    for i in range(3):\n",
    "        tweets = [re.sub(r'(.*)\\s*https?://.+\\s*(.*)', r'\\1 \\2', tweet) for tweet in tweets]\n",
    "\n",
    "    # remove whitespace from beginning and end\n",
    "    tweets = [tweet.rstrip().lstrip() for tweet in tweets]\n",
    "\n",
    "    # replace &amp; with &\n",
    "    tweets = [re.sub(r'&amp;', r'&', tweet) for tweet in tweets]\n",
    "\n",
    "    # condense multiple spaces\n",
    "    tweets =[re.sub(r'\\s+', r' ', tweet) for tweet in tweets]\n",
    "\n",
    "    # return result for all tweets that are not empty now after the cleaning\n",
    "    return [tweet for tweet in tweets if tweet != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trump_tweets = filter_and_clean_tweets(trump_tweets)\n",
    "other_tweets = filter_and_clean_tweets(other_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schauen wir uns das schnell an (mit irgendwelchen zufälligen Indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_tweets[42:45]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, nun haben wir unsere Trainingsdaten. Machen wir daraus einen Pandas DataFrame, damit können wir die Daten flexibel umformen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstelle einen DataFrame mit einem Tweet pro Zeile und mit zwei Spalten, eine Spalte mit dem tweet Text aller Trump und NotTrump tweets und eine mit dem Label: für Trump-Tweets 1 und für die anderen 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Erstelle den Pandas DataFrame wie oben beschrieben\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(...)\n",
    "\n",
    "df.columns=['tweet', 'label'] # verwende diese zwei Spaltennamen\n",
    "df.sample(frac=0.001) # anstelle df.head(), denn damit sähen wir nur Trump tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "#### Vorschlag zur Umsetzung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Es gibt viele Möglichkeiten, wie man diesen DataFrame erstellen kann.\n",
    "# Hier eine kompakte, auch wenn vielleicht nicht die leserlichste\n",
    "# Das .T am schluss dreht den DataFrame (.T für transpose)\n",
    "df = pd.DataFrame([trump_tweets+other_tweets, [1]*len(trump_tweets)+[0]*len(other_tweets)]).T\n",
    "\n",
    "df.columns=['tweet', 'label']\n",
    "df.sample(frac=0.001) # anstelle df.head(), denn damit sähen wir nur Trump tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun schauen wir uns das API von Monkeylearn an. Einige Beispiele des Python-APIs sind [hier](https://github.com/monkeylearn/monkeylearn-python), und hier ist die gesamte [API Referenz](https://monkeylearn.com/docs/article/api-reference/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir initialisieren das API und ertstellen ein Modell. Wähle im untenstehenden Code einen eigenen Classifier-Namen, möglichst so, dass die anderen Workshop-Teilnehmer nicht den gleichen Namen erwischen. Führe dann den Code aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from monkeylearn import MonkeyLearn\n",
    "\n",
    "API_KEY = 'XXX'\n",
    "\n",
    "# Erstelle ein ml Objekt\n",
    "ml = MonkeyLearn(API_KEY)\n",
    "\n",
    "# Erstelle einen Klassifier. ACHTUNG: Mit dem zur Verfügung stehenden API Key\n",
    "# können maximal 3 Classifier gleichzeitig erstellt werden!\n",
    "res = ml.classifiers.create(übergib hier einen eigenen String)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit dem Account, den wir verwenden, können genau 12 Classifiers erstellt werden. Bitte erstelle deshalb nur einen Classifier, damit die anderen Workshop-Teilnehmer auch einen machen können. Musst Du einen Classifier löschen, melde Dich bei mir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schau Dir nun das oben verlinkten Beispiel (github) an und vervollständige den folgenden Code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vervollständige\n",
    "\n",
    "# Hohl die ID des neuen Moduls\n",
    "module_id = ...\n",
    "\n",
    "# Hohl den Root Node\n",
    "root_id = ...\n",
    "\n",
    "# Erstelle zwei neue Kategorien positive_id und negative_id mit den Bezeichnern 'Trump' (pos) und NotTrump' (neg)\n",
    "...\n",
    "positive_id = ...\n",
    "negative_id = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "#### Vorschlag zur Umsetzung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# Hohl die ID des neuen Moduls\n",
    "module_id = res.result['classifier']['hashed_id']\n",
    "\n",
    "# Hohl den Root Node\n",
    "res = ml.classifiers.detail(module_id)\n",
    "root_id = res.result['sandbox_categories'][0]['id']\n",
    "\n",
    "# Erstelle zwei neue Kategorien mit den Bezeichnern 'Trump' und NotTrump'\n",
    "res = ml.classifiers.categories.create(module_id, 'Trump', root_id)\n",
    "positive_id = res.result['category']['id']\n",
    "res = ml.classifiers.categories.create(module_id, 'NotTrump', root_id)\n",
    "negative_id = res.result['category']['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir müssen in unserem DataFrame die Labels (bisher 1 für Trump und 0 für Nicht-Trump) durch die obigen `positive_id`  und `negative_id` ersetzen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ändere im DataFrame 'trump' in positive_id und 'other' in negative_id\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "#### Vorschlag zur Umsetzung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# Auch hier wieder diverse Möglichkeiten, hier eine davon\n",
    "df['label'] = df['label'].map(lambda x: positive_id if x==1 else negative_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun teilen wir wie im follow-along Beispiel unsere Daten in ein Trainings- und ein Validierungsset auf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Teile die Daten in 80% Trainingsdaten und 20% Validierungsdaten\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "#### Vorschlag zur Umsetzung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df['tweet'], df['label'], train_size=0.8, stratify=df['label']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "Da wir deutlich mehr Tweets von Trump haben als andere, müssen wir dafür sorgen, dass dieses Verhältnis innerhalb der Aufteilungen in Trainingsdaten und Validierungsdaten gleich bleibt. Dies erledigt der Parameter `stratified`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Monkeylearn API verlangt die Samples für das Training als Liste, deren Elemente 2-Tupel sind.\n",
    "Ein solches Tupel beinhaltet den Text und eine der beiden oben generierten IDs, also zum Beispiel `('trump tweet text', positive_id)`.\n",
    "\n",
    "Nun haben wir aber dummerweise während dem Umformen den Datentyp des Labels geändert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(type(positive_id), type(y_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das müssen wir wieder ändern, da Monkeylearn nicht mit Numpy Datentypen umgehen kann. Ich werde das als Verbesserungsvorschlag melden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_int = [i.item() for i in y_train.values]\n",
    "del y_train\n",
    "y_train = y_train_int\n",
    "y_test_int = [i.item() for i in y_test.values]\n",
    "del y_test\n",
    "y_test = y_test_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Erstelle eine Liste aus X_train und y_train\n",
    "\n",
    "samples = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "#### Vorschlag zur Umsetzung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# Auch hier gibt es viele Wege, zum Ziel zu kommen. Der kürzeste:\n",
    "samples = zip(X_train, y_train_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun können wir den Classifier trainieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Samples uploaden\n",
    "# auch hier etwas unschön, dass Monkeylearn keine Iteratoren und nur Listen annimmt\n",
    "res = ml.classifiers.upload_samples(module_id, list(samples))\n",
    "\n",
    "# Trainieren\n",
    "res = ml.classifiers.train(module_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Nun validieren wir das Modell mit unserem Validierungsset. Orientiere Dich wiederm am Beispiel wie vorher.\n",
    "\n",
    "**Achtung**: Da die verfügbaren Requests beschränkt sind, pass bitte auf, dass Du keine Endlosloops baust. Für den gesamten Workshop stehen für alle Teilnehmer zusammen 150'000 Queries zur Verfügung, was eigentlich vorig reichen sollte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Mache predictions für das ganze Validierungsset. Speichere sie vorerst so, wie sie von Monkeylearn zurückkommen.\n",
    "predictions = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "#### Vorschlag zur Umsetzung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "predictions = ml.classifiers.classify(module_id, X_test, sandbox=True).result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, eine Prediction sieht so aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das ist etwas unpraktisch, extrahieren wir das."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extrahiere die vorhergesagte category_id aus den predictions in eine separate Liste\n",
    "pred = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "#### Vorschlag zur Umsetzung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "pred = [p[0]['category_id'] for p in predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun berechnen wir die Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nicht schlecht! 88% der Samples wurden korrekt klassifiziert. Damit wären wir am Ende dieses Toy Projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Wenn Du möchtest, kannst nun etwas weiter experimentieren.\n",
    "\n",
    "Aufschlussreich ist es beispielsweise, sich einmal das Dashboard von [Monkeylearn](https://monkeylearn.com) anzuschauen. Dazu müsstest Du Dich aber selber dort registrieren. Für den Free Tier braucht es lediglich eine Email-Adresse, damit kannst Du Modelle mit maximal 3000 Samples trainieren und 1000 Requests machen. Trainieren zählt nicht zu den Requests.\n",
    "\n",
    "Du kannst auch auf den Team Tier upgraden, dann bekommst Du 300'000 Requests. Dafür benötigst Du aber eine Kreditkarte, und nach 14 Tagen wird diese belastet, wenn Du vorher nicht kündigst.\n",
    "\n",
    "Alternativ kannst Du das Dashboard und Deinen Klassifier auch kurz auf meinem Laptop anschauen.\n",
    "\n",
    "----\n",
    "\n",
    "Weitere Ideen:\n",
    "* Ein paar neuere Trump tweets klassifizieren und schauen, ob unser Detektor diese auch als von Trump stammend erkennt. Tweets von 2017 sind im Image vorhanden.\n",
    "* Tweets von jemand anderes als Trump und Ben Carson klassifizieren und schauen, ob unser Detektor diese auch als Nicht-Trump-Tweets erkennt\n",
    "* Hillary Clinton hinyunehmen und zwischen allen dreien unterscheiden. Tip: Das Modell muss nicht neu erstellt werden, es reicht, nur die neuen Tweets von Hillary hinzuzufügen und nochmals zu trainieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wichtig**: Wenn Du Deinen Classifier nicht mehr brauchst, so lösche ihn doch bitte gleich:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml.classifiers.delete(module_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
